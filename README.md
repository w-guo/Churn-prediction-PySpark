# Customer Churn Prediction using PySpark

This repository contains a Jupyter notebook `Sparkify_mini.ipynb` that documents an end-to-end model development process performed on a simulated streaming service dataset using Python API for Spark, `PySpark`.

### Project overview

Predicting customer churn is a challenging and common problem for any e-commerce business in which everything depends on the behavior of customers. Customer churn is often defined as the process in which the customers downgrade from premium to free tier or stop using the products or services of a business. Thus, the ability to predict which users are at risk of churning, while there is still time to offer them discounts or other incentives, will greatly help to prevent every custormer-facing business from suffering severe financial losses.

### Problem statement

The dataset in this project is provided by Sparkify, a fictitious digital music service created by Udacity, to resemble the data sets generated by companies such as Spotify or Pandora. The full dataset collects over 26 million records from 22277 registered users, whereas a smaller subset contains 286500 records from 225 registered users with a duration of about two months. Our goal is to help Spakify identify potential churn users by building and training a binary classifier in order to save the business millions in revenue. More details can be found [blog post](https://wguo.rbind.io/post/sparkify-churn-prediction/)

### Get started

This repository contains the following files:

* `Sparkify_mini.ipynb`: Jupyter notebook that documents the whole model development process on the smaller dataset including exploratory data analysis, data visualization and discussions
* `Sparkify_full.ipynb`: modularized version of `Sparkify_mini.ipynb` used to train the full dataset on the AWS EMR cluster
* `us_region.csv`: [csv file](https://github.com/cphalpert/census-regions) used in `Sparkify_mini.ipynb` that assigns each state to its geographical division (data source: [U.S. Census Bureau](https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf))

#### Datasets

* The full Sparkify dataset (12GB) can be found at `s3n://udacity-dsnd/sparkify/sparkify_event_data.json`
* The smaller version (128MB) is available at `s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json`
   
#### Prerequisites

In addition to `PySpark`, the following Python libraries are also required to be installed: `Numpy`, `Scipy`, `Pandas`, `Matplotlib`, `seaborn` and `time`.

### Results

The best results obtained on the test set from the three models are summarized in the table below:

| <sub>Classifier</sub>                       | <sub>Parameters</sub>                                    | <sub>Precision</sub> |                     | <sub>Recall</sub>  |                     | <sub>F1 score</sub> |                    |  <sub>AUC-PR</sub>  |
| :------------------------------------------ | :------------------------------------------------------- | :------------------: | :-----------------: | :----------------: | :-----------------: | :-----------------: | :----------------: | :-----------------: |
|                                             |                                                          |  <sub>Overall</sub>  | <sub>Churned</sub>  | <sub>Overall</sub> | <sub>Churned</sub>  | <sub>Overall</sub>  | <sub>Churned</sub> |                     |
| <sub>Logistic regression</sub>              | <sub>maxIter=10, regParam=0.1, elasticNetParam=0.5</sub> |   <sub>0.85</sub>    |   <sub>1.00</sub>   |  <sub>0.82</sub>   |   <sub>0.20</sub>   |   <sub>0.77</sub>   |  <sub>0.33</sub>   |   <sub>0.72</sub>   |
| <sub>Random forest classifier</sub>         | <sub>maxDepth=4, numTrees=100</sub>                      |   <sub>0.86</sub>    | <sub>**0.75**</sub> |  <sub>0.86</sub>   | <sub>**0.60**</sub> | <sub>**0.86**</sub> |  <sub>0.67</sub>   | <sub>**0.77**</sub> |
| <sub>Gradient-boosted tree classifier</sub> | <sub>maxDepth=5, maxIter=100</sub>                       |   <sub>0.77</sub>    |   <sub>0.43</sub>   |  <sub>0.73</sub>   |   <sub>0.60</sub>   |   <sub>0.74</sub>   |  <sub>0.50</sub>   |   <sub>0.65</sub>   |


### Acknowledgements
Credit to Udacity for designing the project and hosting the datasets.

Blog reference: https://medium.com/@lukazaplotnik/sparkify-churn-prediction-with-pyspark-da50652f2afc
