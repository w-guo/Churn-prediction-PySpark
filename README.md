# Customer Churn Prediction using PySpark

This repository contains a Jupyter notebook `Sparkify_mini.ipynb` that documents an end-to-end model development process performed on a simulated streaming service dataset using Python API for Spark, `PySpark`.

### Project overview

Predicting customer churn is a challenging and common problem for any e-commerce business in which everything depends on the behavior of customers. Customer churn is often defined as the process in which the customers downgrade from premium to free tier or stop using the products or services of a business. Thus, the ability to predict which users are at risk of churning, while there is still time to offer them discounts or other incentives, will greatly help to prevent every custormer-facing business from suffering severe financial losses.

### Problem statement

The dataset in this project is provided by Sparkify, a fictitious digital music service created by Udacity, to resemble the data sets generated by companies such as Spotify or Pandora. The full dataset collects approximately 26 million records from 22277 registered users, whereas a smaller subset contains 286500 records from 225 registered users with a duration of about two month. Our goal is to help Spakify identify potential churn users by building and training a binary classifier in order to save the business millions in revenue. [blog post](https://wguo.rbind.io/post/sparkify-churn-prediction/)

### Get started

This repository includes:

* `Sparkify_mini.ipynb`: Jupyter notebook that documents with exploratory data analysis, modelling steps, results, visualizations and discussions
* `Sparkify_full.ipynb`: modularized version of the main Jupyter notebook adapted to train selected models on the AWS EMR cluster
  
#### Prerequisites

In addition to `PySpark`, the following Python libraries are also required to be installed: `Numpy`, `Scipy`, `Pandas`, `Matplotlib`, `seaborn` and `time`.

### Results

The best results obtained on the test set from the three models are summarized in the table below:


| <sub>Classifier</sub>                       | <sub>Parameters</sub>                                    | <sub>Precision</sub> |                     | <sub>Recall</sub>  |                     | <sub>F1 score</sub> |                    |  <sub>AUC-PR</sub>  |
| :-------------------------- | :-------------------------- | :------------------: | :-----------------: | :----------------: | :-----------------: | :-----------------: | :----------------: | :-----------------: |
|                                             |                                                          |  <sub>Overall</sub>  | <sub>Churned</sub>  | <sub>Overall</sub> | <sub>Churned</sub>  | <sub>Overall</sub>  | <sub>Churned</sub> |                     |
| <sub>Logistic regression</sub>              | <sub>maxIter=10, regParam=0.1, elasticNetParam=0.5</sub> |   <sub>0.85</sub>    |   <sub>1.00</sub>   |  <sub>0.82</sub>   |   <sub>0.20</sub>   |   <sub>0.77</sub>   |  <sub>0.33</sub>   |   <sub>0.72</sub>   |
| <sub>Random forest classifier</sub>         | <sub>maxDepth=4, numTrees=100</sub>                      |   <sub>0.86</sub>    | <sub>**0.75**</sub> |  <sub>0.86</sub>   | <sub>**0.60**</sub> | <sub>**0.86**</sub> |  <sub>0.67</sub>   | <sub>**0.77**</sub> |
| <sub>Gradient-boosted tree classifier</sub> | <sub>maxDepth=5, maxIter=100</sub>                       |   <sub>0.77</sub>    |   <sub>0.43</sub>   |  <sub>0.73</sub>   |   <sub>0.60</sub>   |   <sub>0.74</sub>   |  <sub>0.50</sub>   |   <sub>0.65</sub>   |


### Acknowledgements
Credit to Udacity for designing the project and hosting the datasets:

* The full Sparkify dataset (12GB) can be found at `s3n://udacity-dsnd/sparkify/sparkify_event_data.json`

* The smaller version used for data exploration (128MB) is available at `s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json`

Blog reference: 
* https://medium.com/@lukazaplotnik/sparkify-churn-prediction-with-pyspark-da50652f2afc
